{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.activations import sigmoid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.py\n",
    "\n",
    "Contains relevant functions to rest of code. Vectorized, preprocessing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale between -15 and 15\n",
    "def preprocess_scores(scores):\n",
    "    for i, score in enumerate(scores):\n",
    "        score = str(score).encode('utf-8')\n",
    "        score = score.decode('utf-8-sig')\n",
    "        \n",
    "        if score[0:2] == '#+':\n",
    "            score = 20\n",
    "        elif score[0:2] == '#-':\n",
    "            score = -20\n",
    "        elif int(score) > 15:\n",
    "            score = 15\n",
    "        elif int(score) < -15:\n",
    "            score = -15\n",
    "        \n",
    "        scores[i] = int(score)\n",
    "    \n",
    "    scores = scores.astype('float32')\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# return bit arrays from FEN string\n",
    "def vectorize(fen):\n",
    "    data = re.split(\" \", fen)\n",
    "    rows= re.split(\"/\", data[0])\n",
    "    turn = data[1]\n",
    "    can_castle = data[2]\n",
    "    passant = data[3]\n",
    "    half_moves = data[4]\n",
    "    full_moves = data[5]\n",
    "    \n",
    "    bit_vector = np.zeros((13, 8, 8), dtype=np.float32)\n",
    "    \n",
    "    #what layer each piece is found on\n",
    "    piece_to_layer = {\n",
    "            'R': 1,\n",
    "            'N': 2,\n",
    "            'B': 3,\n",
    "            'Q': 4,\n",
    "            'K': 5,\n",
    "            'P': 6,\n",
    "            'p': 7,\n",
    "            'k': 8,\n",
    "            'q': 9,\n",
    "            'b': 10,\n",
    "            'n': 11,\n",
    "            'r': 12\n",
    "        }\n",
    "    #find each piece based on type\n",
    "    for r,value in enumerate(rows):\n",
    "        colum = 0\n",
    "        for piece in value:\n",
    "            if piece in piece_to_layer:\n",
    "                bit_vector[piece_to_layer[piece],r,colum] =1\n",
    "                colum += 1\n",
    "            else:\n",
    "                colum += int(piece)\n",
    "    \n",
    "    if turn.lower() == 'w':\n",
    "        bit_vector [0,7,4] =1\n",
    "    else:\n",
    "        bit_vector [0,0,4] =1\n",
    "        \n",
    "    #where each castle bit is located\n",
    "    castle ={\n",
    "        'k': (0,0),\n",
    "        'q': (0,7),\n",
    "        'K': (7,0),\n",
    "        'Q': (7,7),\n",
    "        }\n",
    "\n",
    "    for value in can_castle:\n",
    "        if value in castle:\n",
    "            bit_vector[0,castle[value][0],castle[value][1]] = 1\n",
    "    \n",
    "    #put en-passant square in the vector\n",
    "    if passant != '-':\n",
    "        bit_vector[0,  5 if (int(passant[1])-1 == 3) else 2 , ord(passant[0]) - 97,] = 1\n",
    "    \n",
    "    return bit_vector # we did a .reshape(something)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequenceTest.py\n",
    "\n",
    "Contains code from relevant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into banches so we can actually process this thing.\n",
    "class DataSequence(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, file, batch_size):\n",
    "        self.file = file\n",
    "        self.batch_size = batch_size\n",
    "      \n",
    "    def __len__(self):\n",
    "        #total_length = sum(1 for row in open(self.file))\n",
    "        total_length = 100_000\n",
    "        return int(np.ceil(total_length) / self.batch_size)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        df = pd.read_csv(self.file, skiprows=idx*self.batch_size, nrows=self.batch_size)\n",
    "      \n",
    "        x = np.ndarray(shape=(self.batch_size,13,8,8))\n",
    "        y = np.array(df.iloc[:,1])\n",
    "      \n",
    "        #have preprocessing here right now for testing, should save processed scores in file\n",
    "        # once we decide how to do this\n",
    "        for i, f in enumerate(df.iloc[:,0]):\n",
    "            x[i] = vectorize(f)\n",
    "        x = x.reshape((self.batch_size,832))\n",
    "        y = preprocess_scores(y)\n",
    "        #print(x.shape, y.shape)\n",
    "        #print(idx)\n",
    "        \n",
    "        return (x, y)\n",
    "    \n",
    "# does ?\n",
    "def scaled_sigmoid(x):\n",
    "    #print(2  * sigmoid(x) - 1)\n",
    "    return 2  * sigmoid(x) - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training.py\n",
    "\n",
    "Contains code from relevant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(13, 8, 8)),\n",
    "    tf.keras.layers.Dense(832, activation='linear'),\n",
    "    tf.keras.layers.Dense(832, activation='relu'),\n",
    "    tf.keras.layers.Dense(832, activation='linear'),\n",
    "    tf.keras.layers.Dense(832, activation='relu'),\n",
    "    tf.keras.layers.Dense(832, activation='linear'),\n",
    "    tf.keras.layers.Dense(832, activation='relu'),\n",
    "    #tf.keras.layers.Dense(1, activation=scaled_sigmoid)\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='MeanAbsoluteError')\n",
    "\n",
    "# df = pd.read_csv(\"../data/kaggleDataset/chessData.csv\", \n",
    "#      nrows=10000, dtype={'FEN':str, 'Evaluation':str})\n",
    "\n",
    "train_sequence = DataSequence(\"../data/kaggleDataset/chessData.csv\", 1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to used 'vectorized.csv'\n",
    "\n",
    "It is not returning in exactly the way we'd like, so I'm trying to deal with this here. Idk if this will work, that's why I need to try and plug it in to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the 'vectorized' things to the array type again. This feels like 2 steps backwards 1 forward\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def toArray(fen_string):\n",
    "    formatted_string = re.sub(r'\\[|\\]', '', fen_string)\n",
    "\n",
    "    # Split the string into separate blocks of 13 8x8 arrays\n",
    "    fen_blocks = formatted_string.split('\\n\\n ')\n",
    "\n",
    "    # Define a function to convert a single FEN block to a 3D list\n",
    "    def fen_to_3d_array(fen_block):\n",
    "        rows = fen_block.split('\\n')\n",
    "        return [[[int(cell) for cell in row.split()] for row in rows[i:i + 8]] for i in range(0, len(rows), 8)]\n",
    "\n",
    "    # Convert each FEN block to a 3D list\n",
    "    fen_arrays = [fen_to_3d_array(fen_block) for fen_block in fen_blocks]\n",
    "\n",
    "    # Convert to numpy array and check the shape\n",
    "    return np.asarray(fen_arrays).reshape(13,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nrows = 50_000\n",
    "\n",
    "df = pd.read_csv(\"../data/createdData/vectorized.csv\", nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x\n",
    "dfcopy = df.copy().head(100)[['FEN','Evaluation']]\n",
    "x = dfcopy.FEN.apply(toArray)\n",
    "\n",
    "# y\n",
    "y = preprocess_scores(dfcopy.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 100 into shape (100,13,8,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49masarray(x)\u001b[39m.\u001b[39;49mreshape(\u001b[39m100\u001b[39;49m,\u001b[39m13\u001b[39;49m,\u001b[39m8\u001b[39;49m,\u001b[39m8\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 100 into shape (100,13,8,8)"
     ]
    }
   ],
   "source": [
    "np.asarray(x).reshape(100,13,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(dfcopy\u001b[39m.\u001b[39;49mFEN, dfcopy\u001b[39m.\u001b[39;49mEvaluation, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "model.fit(dfcopy.FEN, dfcopy.Evaluation, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 10s 90ms/step - loss: 11.7550\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 9s 92ms/step - loss: 10.1932\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 9s 91ms/step - loss: 9.4187\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 9s 97ms/step - loss: 8.8498\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 10s 103ms/step - loss: 7.9005\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 10s 104ms/step - loss: 7.1467\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 11s 109ms/step - loss: 6.2788\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 12s 119ms/step - loss: 5.5755\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 17s 177ms/step - loss: 4.9788\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 15s 150ms/step - loss: 4.4582\n",
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_sequence, epochs=10)\n",
    "\n",
    "model.save('saved_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runSavedBot.py\n",
    "\n",
    "(Currently not evaluating)\n",
    "\n",
    "Contains code from relevant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import chess\n",
    "\n",
    "# import utils\n",
    "\n",
    "# def evaluate(board):\n",
    "#     #print(vectorize(board.fen()).shape)\n",
    "#     evaluation = model.predict_step(utils.vectorize(board.fen()).reshape((1,832)))\n",
    "#     #print(evaluation)\n",
    "#     return evaluation\n",
    "\n",
    "# def find_best_move(board, depth, maximizing_player):\n",
    "#     if maximizing_player:\n",
    "#         best_score = float('-inf')\n",
    "#         best_move = None\n",
    "#         for move in board.legal_moves:\n",
    "#             board.push(move)\n",
    "#             score = minimax(board, depth - 1, float('-inf'), float('inf'), False)\n",
    "#             print(move, score)\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_move = move\n",
    "#             board.pop()\n",
    "#     else:\n",
    "#         best_score = float('inf')\n",
    "#         best_move = None\n",
    "#         for move in board.legal_moves:\n",
    "#             board.push(move)\n",
    "#             score = minimax(board, depth - 1, float('-inf'), float('inf'), True)\n",
    "#             if score < best_score:\n",
    "#                 best_score = score\n",
    "#                 best_move = move\n",
    "#             board.pop()\n",
    "    \n",
    "#     return best_move\n",
    "    \n",
    "# def minimax(board, depth, alpha, beta, maximizing_player):\n",
    "#     if board.is_game_over() or depth == 0:\n",
    "#         return evaluate(board)\n",
    "    \n",
    "#     if maximizing_player:\n",
    "#         best_score = float('-inf')\n",
    "#         for move in board.legal_moves:\n",
    "#             board.push(move)\n",
    "#             score = minimax(board, depth-1, alpha, beta, False)\n",
    "#             #score += depth\n",
    "#             board.pop()\n",
    "#             best_score = max(score, best_score)\n",
    "#             alpha = max(alpha, best_score)\n",
    "#             if alpha >= beta:\n",
    "#                 break\n",
    "#         return best_score\n",
    "#     else:\n",
    "#         best_score = float('inf')\n",
    "#         for move in board.legal_moves:\n",
    "#             board.push(move)\n",
    "#             score = minimax(board, depth-1, alpha, beta, True)\n",
    "#             #score -= depth\n",
    "#             board.pop()\n",
    "#             best_score = min(score, best_score)\n",
    "#             beta = min(beta, best_score)\n",
    "#             if alpha >= beta:\n",
    "#                 break\n",
    "#         return best_score\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model = tf.keras.models.load_model('saved_model')\n",
    "    \n",
    "#     board = chess.Board()\n",
    "#     depth = 3\n",
    "\n",
    "#     while not board.is_game_over():\n",
    "#         print(board)\n",
    "#         print()\n",
    "\n",
    "#         if board.turn == chess.WHITE:\n",
    "#             move = find_best_move(board, depth, True)\n",
    "#             print(move)\n",
    "#         else:\n",
    "#             move = chess.Move.from_uci(input(prompt='Move: '))\n",
    "            \n",
    "\n",
    "#         board.push(move)\n",
    "\n",
    "#     print(\"Game over\")\n",
    "#     print(\"Result:\", board.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
