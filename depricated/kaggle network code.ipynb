{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boardstate(fen):\n",
    "    board = chess.Board(fen[0])\n",
    "    fstr = str(fen[0])\n",
    "\n",
    "    if board.has_kingside_castling_rights(chess.WHITE) == True:\n",
    "        WCKI = 1\n",
    "    else:\n",
    "        WCKI = 0\n",
    "    if board.has_queenside_castling_rights(chess.WHITE) == True:\n",
    "        WCQ = 1\n",
    "    else:\n",
    "        WCQ = 0\n",
    "    if board.is_check() == True:\n",
    "        WCH = 1\n",
    "    else:\n",
    "        WCH = 0\n",
    "\n",
    "    if board.has_kingside_castling_rights(chess.BLACK) == True:\n",
    "        BCKI = 1\n",
    "    else:\n",
    "        BCKI = 0\n",
    "    if board.has_queenside_castling_rights(chess.BLACK) == True:\n",
    "        BCQ = 1\n",
    "    else:\n",
    "        BCQ = 0\n",
    "    if board.was_into_check() == True:\n",
    "        BCH = 1\n",
    "    else:\n",
    "        BCH = 0\n",
    "\n",
    "    #f = [M, WCKI, WCQ, WCH, BCKI, BCQ, BCH]\n",
    "    fw = [WCKI, WCQ, WCH]\n",
    "    fb = [BCKI, BCQ, BCH]\n",
    "\n",
    "    bstr = str(board)\n",
    "    bstr = bstr.replace(\"p\", \"\\ -1\")\n",
    "    bstr = bstr.replace(\"n\", \"\\ -3\")\n",
    "    bstr = bstr.replace(\"b\", \"\\ -4\")\n",
    "    bstr = bstr.replace(\"r\", \"\\ -5\")\n",
    "    bstr = bstr.replace(\"q\", \"\\ -9\")\n",
    "    bstr = bstr.replace(\"k\", \"\\ -100\")\n",
    "    bstr = bstr.replace(\"P\", \"\\ 1\")\n",
    "    bstr = bstr.replace(\"N\", \"\\ 3\")\n",
    "    bstr = bstr.replace(\"B\", \"\\ 4\")\n",
    "    bstr = bstr.replace(\"R\", \"\\ 5\")\n",
    "    bstr = bstr.replace(\"Q\", \"\\ 9\")\n",
    "    bstr = bstr.replace(\"K\", \"\\ 100\")\n",
    "    bstr = bstr.replace(\".\", \"\\ 0\")\n",
    "    bstr = bstr.replace(\"\\ \", \",\")\n",
    "    bstr = bstr.replace(\"'\", \" \")\n",
    "    bstr = bstr.replace(\"\\n\", \"\")\n",
    "    bstr = bstr.replace(\" \", \"\")\n",
    "    bstr = bstr[1:]\n",
    "    bstr = eval(bstr)\n",
    "    bstr = list(bstr)\n",
    "    if \"w\" not in fstr:\n",
    "        for i in range(len(bstr)):\n",
    "            bstr[i] = bstr[i] * -1\n",
    "        bstr.reverse()\n",
    "        fs = fb\n",
    "        fb = fw\n",
    "        fw = fs\n",
    "\n",
    "\n",
    "    BITBOARD = fw + fb + bstr\n",
    "\n",
    "\n",
    "    return BITBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = ''\n",
    "#r = 1\n",
    "def strfix(tr):\n",
    "    if '#' in str(tr):\n",
    "        if '-' in tr:\n",
    "            t = -1000\n",
    "        else:\n",
    "            t = 1000\n",
    "    elif '\\ufeff+23' in str(tr):\n",
    "        t = 0\n",
    "    else:\n",
    "        t = int(tr)\n",
    "    \n",
    "    t = t/100\n",
    "    #try:\n",
    "    #    t = int(t)\n",
    "    #except ValueError:\n",
    "    #    t = 0\n",
    "\n",
    "    return t\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m data_labels \u001b[39m=\u001b[39m data_labels\u001b[39m.\u001b[39mhead(\u001b[39m1000000\u001b[39m)\n\u001b[0;32m     15\u001b[0m data_labels \u001b[39m=\u001b[39m data_labels\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \n\u001b[1;32m---> 18\u001b[0m data_labels \u001b[39m=\u001b[39m data_labels\u001b[39m.\u001b[39;49mapply(strfix, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m \u001b[39m#print(data_features)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m#print(data_labels)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m#print(data_labels.dtypes)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m data_features \u001b[39m=\u001b[39m data_features\u001b[39m.\u001b[39mapply(boardstate, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mstrfix\u001b[1;34m(tr)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         t \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m\\ufeff\u001b[39;00m\u001b[39m+23\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39;49m(tr):\n\u001b[0;32m     10\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\series.py:1594\u001b[0m, in \u001b[0;36mSeries.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1590\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m \u001b[39mReturn a string representation for a particular Series.\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m repr_params \u001b[39m=\u001b[39m fmt\u001b[39m.\u001b[39mget_series_repr_params()\n\u001b[1;32m-> 1594\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_string(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrepr_params)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\core\\series.py:1687\u001b[0m, in \u001b[0;36mSeries.to_string\u001b[1;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows, min_rows)\u001b[0m\n\u001b[0;32m   1641\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \u001b[39mRender a string representation of the Series.\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[39m    String representation of Series if ``buf=None``, otherwise None.\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m formatter \u001b[39m=\u001b[39m fmt\u001b[39m.\u001b[39mSeriesFormatter(\n\u001b[0;32m   1676\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1677\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m     max_rows\u001b[39m=\u001b[39mmax_rows,\n\u001b[0;32m   1686\u001b[0m )\n\u001b[1;32m-> 1687\u001b[0m result \u001b[39m=\u001b[39m formatter\u001b[39m.\u001b[39;49mto_string()\n\u001b[0;32m   1689\u001b[0m \u001b[39m# catch contract violations\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\io\\formats\\format.py:415\u001b[0m, in \u001b[0;36mSeriesFormatter.to_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m     fmt_index\u001b[39m.\u001b[39minsert(row_num \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex:\n\u001b[1;32m--> 415\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madj\u001b[39m.\u001b[39;49madjoin(\u001b[39m3\u001b[39;49m, \u001b[39m*\u001b[39;49m[fmt_index[\u001b[39m1\u001b[39;49m:], fmt_values])\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj\u001b[39m.\u001b[39madjoin(\u001b[39m3\u001b[39m, fmt_values)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\io\\formats\\format.py:439\u001b[0m, in \u001b[0;36mTextAdjustment.adjoin\u001b[1;34m(self, space, *lists, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madjoin\u001b[39m(\u001b[39mself\u001b[39m, space: \u001b[39mint\u001b[39m, \u001b[39m*\u001b[39mlists, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m adjoin(space, \u001b[39m*\u001b[39mlists, strlen\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlen, justfunc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjustify, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\pandas\\io\\formats\\printing.py:43\u001b[0m, in \u001b[0;36madjoin\u001b[1;34m(space, *lists, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madjoin\u001b[39m(space: \u001b[39mint\u001b[39m, \u001b[39m*\u001b[39mlists: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    Glues together two sets of strings using the amount of space requested.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    The idea is to prettify.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m        function used to justify str. Needed for unicode handling.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     strlen \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mstrlen\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mlen\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m     justfunc \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mjustfunc\u001b[39m\u001b[39m\"\u001b[39m, justify)\n\u001b[0;32m     46\u001b[0m     out_lines \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data\\chessData.csv\")\n",
    "\n",
    "# print(data)\n",
    "\n",
    "label_columns = [1]\n",
    "\n",
    "data_features = data.drop(columns=data.iloc[:, label_columns])\n",
    "\n",
    "data_features = data_features.head(1000000)\n",
    "\n",
    "data_labels = data.iloc[:, label_columns]\n",
    "\n",
    "data_labels = data_labels.head(1000000)\n",
    "\n",
    "data_labels = data_labels.astype(str) \n",
    "\n",
    "\n",
    "data_labels = data_labels.apply(strfix, axis=1)\n",
    "\n",
    "\n",
    "#print(data_features)\n",
    "\n",
    "#print(data_labels)\n",
    "\n",
    "#print(data_labels.dtypes)\n",
    "\n",
    "data_features = data_features.apply(boardstate, axis=1)\n",
    "\n",
    "data_features = data_features.apply(pd.Series)\n",
    "\n",
    "#print(data_features)\n",
    "\n",
    "input2_columns = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "inputboard = data_features.drop(columns=data_features.iloc[:, input2_columns]) \n",
    "\n",
    "#print(inputboard.dtypes)\n",
    "\n",
    "inputboard = np.array(inputboard)\n",
    "#print(inputboard.shape)\n",
    "\n",
    "#print(inputboard)\n",
    "\n",
    "\n",
    "inputmeta = data_features.iloc[:, input2_columns]\n",
    "\n",
    "#print(inputmeta.dtypes)\n",
    "\n",
    "inputmeta = np.array(inputmeta)\n",
    "#print(inputmeta.shape)\n",
    "\n",
    "print(inputmeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "input1 = tf.keras.layers.Input(shape=(64,))\n",
    "shape1 = tf.keras.layers.Reshape(target_shape=(8, 8, 1))(input1)\n",
    "conv1 = tf.keras.layers.Conv2D(kernel_size=(8,8), padding=\"same\", activation=\"relu\", filters=64, input_shape=(8,8,1))(shape1)\n",
    "bn1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05)(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(kernel_size=(8,8), padding=\"same\", activation=\"relu\", filters=64, input_shape=(8,8,1))(bn1)\n",
    "bn2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05)(conv2)\n",
    "flatten1 = tf.keras.layers.Flatten()(bn2)\n",
    "input2 = tf.keras.layers.Input(shape=(6,))\n",
    "\n",
    "conc = tf.keras.layers.concatenate([flatten1,input2])\n",
    "\n",
    "Denselayer1 = tf.keras.layers.Dense(1024, activation='relu')(conc)\n",
    "Denselayer2 = tf.keras.layers.Dense(512, activation='relu')(Denselayer1)\n",
    "Denselayer3 = tf.keras.layers.Dense(256, activation='relu')(Denselayer2)\n",
    "Denselayer4 = tf.keras.layers.Dense(256, activation='relu')(Denselayer3)\n",
    "Output = tf.keras.layers.Dense(1, activation='linear')(Denselayer4)\n",
    "\n",
    "\n",
    "\n",
    "data_model = tf.keras.models.Model(inputs=[input1, input2], outputs=Output)\n",
    "\n",
    "predictions = data_model([(inputboard[:1]), (inputmeta[:1])]).numpy\n",
    "\n",
    "metric =[tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(clipnorm=1)\n",
    "\n",
    "los = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "data_model.compile(optimizer=opt, \n",
    "                   loss=los,\n",
    "                   metrics=metric)\n",
    "data_model.summary()\n",
    "data_model.fit([inputboard, inputmeta], data_labels, epochs=1000, batch_size=8192, shuffle=True)\n",
    "\n",
    "data_model.save(\"engine01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
